
import argparse
import math
import os
import sys
import warnings
from typing import Tuple

import joblib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.model_selection import KFold, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from statsmodels.api import OLS, add_constant

warnings.filterwarnings("ignore")

# ----------------------------- Utilities -----------------------------

def seed_everything(seed: int = 42):
    np.random.seed(seed)


def check_binary_treatment(d: pd.Series) -> bool:
    unique = np.unique(d.dropna())
    return set(unique) <= {0, 1}


# ----------------------------- Data -----------------------------

def generate_synthetic_data(n: int = 2000, p: int = 10, seed: int = 42) -> pd.DataFrame:
    """Generate synthetic data with heterogenous treatment effects.
    Data generating process inspired by common causal ML literature.
    Returns a DataFrame with columns X0..X{p-1}, D, Y, and true_tau (for evaluation).
    """
    seed_everything(seed)
    X = np.random.normal(size=(n, p))
    # true heterogeneous treatment effect depends on X
    true_tau = (1 + 0.5 * np.tanh(X[:, 0] + 0.5 * X[:, 1]))  # between ~0.5 and ~1.5

    # propensity depends on X
    logits = -0.2 + 0.5 * X[:, 0] - 0.25 * X[:, 2]
    prop = 1 / (1 + np.exp(-logits))
    D = np.random.binomial(1, prop)

    # baseline outcome
    mu = 2 * X[:, 0] - 0.5 * X[:, 3] + 0.1 * (X[:, 4] ** 2)
    # outcome
    Y = mu + D * true_tau + np.random.normal(scale=1.0, size=n)

    df = pd.DataFrame(X, columns=[f"X{i}" for i in range(p)])
    df["D"] = D
    df["Y"] = Y
    df["true_tau"] = true_tau
    df["propensity"] = prop
    return df


def load_dataframe_from_csv(path: str, treatment: str, outcome: str, drop_na: bool = True) -> pd.DataFrame:
    df = pd.read_csv(path)
    if drop_na:
        df = df.dropna(subset=[treatment, outcome])
    return df


# ----------------------------- Preprocessing -----------------------------

def preprocess(df: pd.DataFrame, treatment: str, outcome: str, feature_cols=None) -> Tuple[pd.DataFrame, np.ndarray, np.ndarray, np.ndarray]:
    """Return (X, D, Y, feature_names).
    If feature_cols is None, use all columns except treatment, outcome, true_tau, propensity.
    This function handles simple numeric imputation and one-hot for categoricals (if any).
    """
    drop_cols = {treatment, outcome, "true_tau", "propensity"}
    if feature_cols is None:
        feature_cols = [c for c in df.columns if c not in drop_cols]

    X = df[feature_cols].copy()
    D = df[treatment].values
    Y = df[outcome].values

    # simple preprocessing pipeline for numeric/categorical separation
    # here we'll do a simple imputer+scaler for numeric; one-hot encoder for categoricals
    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = [c for c in X.columns if c not in numeric_cols]

    # Impute numeric
    if numeric_cols:
        imputer = SimpleImputer(strategy="mean")
        X_num = pd.DataFrame(imputer.fit_transform(X[numeric_cols]), columns=numeric_cols, index=X.index)
    else:
        X_num = pd.DataFrame(index=X.index)

    # One-hot categorical
    if cat_cols:
        ohe = OneHotEncoder(drop="first", sparse=False, handle_unknown="ignore")
        transformed = ohe.fit_transform(X[cat_cols])
        ohe_cols = [f"{col}__{val}" for col in ohe.get_feature_names_out(cat_cols)]
        X_cat = pd.DataFrame(transformed, columns=ohe_cols, index=X.index)
    else:
        X_cat = pd.DataFrame(index=X.index)

    X_processed = pd.concat([X_num, X_cat], axis=1)
    return X_processed, D, Y, X_processed.columns.tolist()


# ----------------------------- DML & DR Learner Implementation -----------------------------

def cross_fit_nuisance_models(X: pd.DataFrame, D: np.ndarray, Y: np.ndarray, n_splits: int = 5, random_state: int = 42):
    """Cross-fit nuisance estimators for g(x)=E[D|X] and m(x)=E[Y|X].
    We'll return predictions for every sample (out-of-fold predictions):
      g_hat (propensity), m_hat (E[Y|X]), m1_hat (E[Y|X,D=1]), m0_hat (E[Y|X,D=0]).
    """
    n = X.shape[0]
    g_hat = np.zeros(n)
    m_hat = np.zeros(n)
    m1_hat = np.zeros(n)
    m0_hat = np.zeros(n)

    kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)

    for train_idx, test_idx in kf.split(X):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        D_train, D_test = D[train_idx], D[test_idx]
        Y_train = Y[train_idx]

        # propensity model
        clf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=random_state)
        clf.fit(X_train, D_train)
        g_hat[test_idx] = clf.predict_proba(X_test)[:, 1]

        # outcome model for all data (S-learner style)
        reg_all = RandomForestRegressor(n_estimators=200, max_depth=8, random_state=random_state)
        reg_all.fit(pd.concat([X_train, pd.DataFrame({"D": D_train})], axis=1), Y_train)

        # to estimate m1 and m0 we create copies of X_test with D=1 and D=0
        X_test_d1 = pd.concat([X_test.reset_index(drop=True), pd.DataFrame({"D": np.ones(len(X_test))})], axis=1)
        X_test_d0 = pd.concat([X_test.reset_index(drop=True), pd.DataFrame({"D": np.zeros(len(X_test))})], axis=1)

        m1_hat[test_idx] = reg_all.predict(X_test_d1)
        m0_hat[test_idx] = reg_all.predict(X_test_d0)

        # m_hat = E[Y|X] can be obtained by predicting with the observed D (or by mixing m1 and m0 using g_hat)
        # We'll predict observable Y using reg_all with observed D
        X_test_obs = pd.concat([X_test.reset_index(drop=True), pd.DataFrame({"D": D_test})], axis=1)
        m_hat[test_idx] = reg_all.predict(X_test_obs)

    return g_hat, m_hat, m1_hat, m0_hat


def estimate_ate_dml(Y: np.ndarray, D: np.ndarray, m_hat: np.ndarray, g_hat: np.ndarray) -> Tuple[float, float]:
    """Estimate ATE via DML/orthogonalization using residual-on-residual regression.
    Returns (ate, se) where se is bootstrap standard error by default (we provide analytic approx below).
    """
    # residuals
    Y_res = Y - m_hat
    D_res = D - g_hat

    # ATE estimator = (D_res' * Y_res) / (D_res' * D_res)
    numerator = np.dot(D_res, Y_res)
    denominator = np.dot(D_res, D_res)
    ate = numerator / denominator

    # influence function based standard error (approx)
    n = len(Y)
    psi = D_res * (Y_res - D_res * ate) / denominator
    se = np.sqrt(np.var(psi, ddof=1) / n)
    return ate, se


def estimate_ate_bootstrap(Y: np.ndarray, D: np.ndarray, X: pd.DataFrame, n_boot: int = 200, random_state: int = 42) -> Tuple[float, Tuple[float, float]]:
    """Bootstrap ATE using full pipeline (re-estimate nuisances per bootstrap sample).
    This is computationally heavier but provides robust intervals.
    Returns (ate_hat, (lower, upper)) 95% CI.
    """
    rng = np.random.RandomState(random_state)
    ates = []
    n = X.shape[0]
    for b in range(n_boot):
        idx = rng.randint(0, n, n)
        Xb = X.iloc[idx].reset_index(drop=True)
        Yb = Y[idx]
        Db = D[idx]
        # cross-fit nuisances on bootstrap sample (we keep folds fixed to speed up but re-fit)
        try:
            g_hat_b, m_hat_b, _, _ = cross_fit_nuisance_models(Xb, Db, Yb, n_splits=5, random_state=random_state)
            ate_b, _ = estimate_ate_dml(Yb, Db, m_hat_b, g_hat_b)
            ates.append(ate_b)
        except Exception:
            continue
    ate_hat = np.mean(ates)
    lower = np.percentile(ates, 2.5)
    upper = np.percentile(ates, 97.5)
    return ate_hat, (lower, upper)


def estimate_cate_dr_learner(X: pd.DataFrame, D: np.ndarray, Y: np.ndarray, g_hat: np.ndarray, m1_hat: np.ndarray, m0_hat: np.ndarray, model_for_tau=None, random_state: int = 42):
    """Doubly Robust (DR) learner for CATE:
    Compute pseudo-outcome:
      pseudo = m1_hat - m0_hat + D*(Y - m1_hat)/g_hat - (1-D)*(Y - m0_hat)/(1-g_hat)
    Then regress pseudo on X to learn CATE(x).
    """
    # sanitize g_hat to avoid division by zero
    eps = 1e-6
    g = np.clip(g_hat, eps, 1 - eps)

    pseudo = m1_hat - m0_hat + (D * (Y - m1_hat) / g) - ((1 - D) * (Y - m0_hat) / (1 - g))

    if model_for_tau is None:
        model_for_tau = GradientBoostingRegressor(n_estimators=200, max_depth=3, random_state=random_state)

    model_for_tau.fit(X, pseudo)
    tau_hat = model_for_tau.predict(X)
    return tau_hat, model_for_tau, pseudo


# ----------------------------- OLS Comparison -----------------------------

def estimate_ols_with_interactions(X: pd.DataFrame, D: np.ndarray, Y: np.ndarray) -> Tuple[np.ndarray, float]:
    """Fit OLS of Y on D, X, and D*X interactions and return predicted CATE (coefficient on D plus interactions).
    This is a high-dimensional OLS if X is large; for interpretability we run a simple linear model.
    """
    X_mat = X.copy()
    # create interactions
    X_int = X_mat.multiply(D, axis=0)
    X_ols = pd.concat([pd.DataFrame({"D": D}), X_mat, X_int.add_prefix("D_x_")], axis=1)
    X_ols = add_constant(X_ols)
    ols_mod = OLS(Y, X_ols).fit()

    # To get CATE for each sample, sum D coefficient + sum interaction coefficients * X
    params = ols_mod.params
    beta_D = params.get("D", 0.0)
    interaction_coefs = params.filter(like="D_x_")
    cate_ols = beta_D + X_mat.dot(interaction_coefs.values)
    return cate_ols, ols_mod


# ----------------------------- Evaluation & Visualization -----------------------------

def evaluate_and_report(df: pd.DataFrame, X: pd.DataFrame, D: np.ndarray, Y: np.ndarray, tau_hat: np.ndarray, true_tau_col: str = "true_tau"):
    print("--- Evaluation ---")
    if true_tau_col in df.columns:
        true_tau = df[true_tau_col].values
        mse = np.mean((tau_hat - true_tau) ** 2)
        print(f"CATE MSE vs truth: {mse:.4f}")
        # show subgroup average treatment effects
        for q in [0.1, 0.25, 0.5, 0.75, 0.9]:
            mask = tau_hat >= np.quantile(tau_hat, q)
            print(f"Avg Y in top {int(q*100)}% by estimated tau: {np.mean(df['Y'].values[mask]):.3f}")


def plot_cate_hist(tau_hat: np.ndarray, title: str = "Estimated CATE distribution"):
    plt.figure(figsize=(6, 4))
    plt.hist(tau_hat, bins=30)
    plt.title(title)
    plt.xlabel("tau_hat")
    plt.ylabel("count")
    plt.tight_layout()
    plt.show()


# ----------------------------- Main pipeline -----------------------------

def run_pipeline(df: pd.DataFrame, treatment: str = "D", outcome: str = "Y", feature_cols=None, demo: bool = False):
    print("Preparing data...")
    X, D, Y, feat_names = preprocess(df, treatment, outcome, feature_cols=feature_cols)
    print(f"Features: {len(feat_names)} columns")

    print("Estimating nuisance models via cross-fitting...")
    g_hat, m_hat, m1_hat, m0_hat = cross_fit_nuisance_models(X, D, Y, n_splits=5)

    print("Estimating ATE via DML...")
    ate, se = estimate_ate_dml(Y, D, m_hat, g_hat)
    print(f"DML ATE = {ate:.4f}, SE (influence-function approx) = {se:.4f}")

    print("Estimating CATE via DR-learner...")
    tau_hat, tau_model, pseudo = estimate_cate_dr_learner(X, D, Y, g_hat, m1_hat, m0_hat)
    print("CATE estimated for each sample.")

    print("Fitting OLS with interactions for baseline comparison...")
    cate_ols, ols_mod = estimate_ols_with_interactions(X, D, Y)
    print(ols_mod.summary())

    # Bootstrap ATE (optional, slower)
    print("(Optional) Running bootstrap ATE (this may take time)...")
    ate_boot, (ci_low, ci_high) = estimate_ate_bootstrap(Y, D, X, n_boot=100)
    print(f"Bootstrap ATE mean = {ate_boot:.4f}, 95% CI = [{ci_low:.4f}, {ci_high:.4f}]")

    # Evaluation if true tau available
    evaluate_and_report(df, X, D, Y, tau_hat)

    # Basic plots
    plot_cate_hist(tau_hat)

    # Save models and outputs to disk
    out_dir = "dml_output"
    os.makedirs(out_dir, exist_ok=True)
    joblib.dump({"tau_model": tau_model, "ols_model": ols_mod}, os.path.join(out_dir, "models.joblib"))
    pd.DataFrame({"tau_hat": tau_hat, "tau_ols": cate_ols, "g_hat": g_hat, "m_hat": m_hat}).to_csv(os.path.join(out_dir, "estimates.csv"), index=False)
    print(f"Saved models and estimates to {out_dir}/")


# ----------------------------- CLI -----------------------------

def main():
    parser = argparse.ArgumentParser(description="DML & DR Learner pipeline for HTE estimation")
    parser.add_argument("--csv", type=str, default=None, help="Path to csv file. If omitted, runs demo synthetic data.")
    parser.add_argument("--treatment", type=str, default="D", help="Treatment column name (binary 0/1)")
    parser.add_argument("--outcome", type=str, default="Y", help="Outcome column name")
    parser.add_argument("--demo", action="store_true", help="Run synthetic demo dataset")
    args = parser.parse_args()

    if args.csv and not args.demo:
        if not os.path.exists(args.csv):
            print(f"CSV not found: {args.csv}")
            sys.exit(1)
        df = load_dataframe_from_csv(args.csv, treatment=args.treatment, outcome=args.outcome)
        run_pipeline(df, treatment=args.treatment, outcome=args.outcome)
    else:
        df = generate_synthetic_data(n=3000, p=10, seed=42)
        run_pipeline(df, treatment="D", outcome="Y", demo=True)


if __name__ == "__main__":
    main()
